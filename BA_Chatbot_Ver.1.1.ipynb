{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfddaa805678f63c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fine-Tune Large Language Model for Behavioral Activation Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df3a326ab242bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.Research Question\n",
    "Behavioral Activation is a therapy method that helps reduce symptoms of depression and mood disorders by promoting involvement in rewarding activities. Recently, Large Language Models (LLMs) like GPT have introduced more intelligent chatbot capabilities. \n",
    "\n",
    "However, these LLMs are generalized for a wide range of conversations and aren't tailored specifically for tasks like Behavioral Activation. The challenge is to adapt these advanced LLMs to effectively assist in Behavioral Activation through chatbot interactions.\n",
    "\n",
    "How could we develop a chatbot that bridge the gap between LLMs' general capabilities and the specific requirements of behavioral activation in a chatbot context?\n",
    "\n",
    "We pick the Chatgpt as our LLM and the Dataset was provided by Florian Onur Kuhlmeier and Sven Scheu.\n",
    "We start with data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123db64237965f90",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.Data Preprocessing for Fine Tuning (final version: messages.jsonl)\n",
    "### Data understanding\n",
    "•\tid: this is the idea of the message (one id per row) -> ignore\n",
    "•\tconversation_id: an ID that signals which conversation the message belongs to.\n",
    "•\tflow_id: this is the id of the therapy session (behavioral activation was made up of three sessions / flows: verhaltenraktivierung-1, verhaltenraktivierung-2, verhaltenraktivierung-3). \n",
    "•\tStep_id: every flow consisted of multiple steps. You can ignore this column.\n",
    "•\tDirection: SEND (by chatbot) vs. RECEIVE (by user)\n",
    "•\tPayload: this is the message content \n",
    "•\tContent_type: which type of content the message has (image, text, question etc.)\n",
    "•\tmessage_order: usable to create the order of the messages (best to check with created_at)\n",
    "•\tcreated_at: date and time of the message -> best column to extract the order of the messages\n",
    "•\tinteraction_order -> ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This dataset comes from a rule based chatbot by Florian Onur Kuhlmeier and Sven Scheu. To get the useful data from this data, we follow these steps:\n",
    "1. Select rows where flow_id equals 'verhaltensaktivierung-2' that contain the most important data that we want to use in the fine-tuning. \n",
    "2. Narrow down to rows where content type is either 'text', 'question', or 'payload', as they are key components of prompt construction and sort the dataset by ‘created_at’.\n",
    "3. Transfer the selected dataset by ‘Payload’ with ‘direction’ mapping  {'SEND': 'assistant', 'RECEIVE': 'user’} to extract conversations into a format that can be used by the LLM\n",
    "4. Process format error checks and perform data analysis according to the OpenAI cookbook guidelines. \n",
    "5. Remove examples that violate OpenAI content policies, when we push data into a fine-tuned model.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83e4124cf3c2581a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.595731800Z",
     "start_time": "2024-03-03T00:35:35.682544900Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\data\\verhaltensaktivierung.parquet.gzip\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd28b346eadfab5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### First image of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479ba6d73264abbc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.613731700Z",
     "start_time": "2024-03-03T00:35:37.596734100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id                       conversation_id  \\\n",
      "0  12d29e68-e636-4fe7-abb8-3d1e3dc661c3  3cc89a19-5742-4f66-a93a-86cad116bea1   \n",
      "1  cbee3172-53b5-4e3f-8bda-9e6a34d5280f  3cc89a19-5742-4f66-a93a-86cad116bea1   \n",
      "2  2bfa2b69-d75d-4e43-8ded-29a7998a101b  3cc89a19-5742-4f66-a93a-86cad116bea1   \n",
      "3  5e019e59-9c04-4e66-a3dc-cd28875b365c  3cc89a19-5742-4f66-a93a-86cad116bea1   \n",
      "4  dc3518c7-f7b0-408d-890b-fc94c23d7af7  3cc89a19-5742-4f66-a93a-86cad116bea1   \n",
      "\n",
      "                   flow_id step_id direction  \\\n",
      "0  verhaltensaktivierung-1   start      SEND   \n",
      "1  verhaltensaktivierung-1   start   RECEIVE   \n",
      "2  verhaltensaktivierung-1   start   RECEIVE   \n",
      "3  verhaltensaktivierung-1   start      SEND   \n",
      "4  verhaltensaktivierung-1   start      SEND   \n",
      "\n",
      "                                             payload  content_type  \\\n",
      "0  {\"content\":{\"url\":\"https://media0.giphy.com/me...         image   \n",
      "1  {\"content\":{\"flow_id\":\"verhaltensaktivierung-1...  flow_trigger   \n",
      "2  {\"content\":{\"payload\":\"Hmm...muss das sein?\"},...       payload   \n",
      "3  {\"content\":{\"text\":\"Um es kurz zu machen: Ich ...          text   \n",
      "4  {\"content\":{\"buttons\":[{\"content\":{\"accepts\":[...      question   \n",
      "\n",
      "   message_order  interaction_order                 created_at  \n",
      "0              2                  0 2023-06-11 10:56:48.985350  \n",
      "1              0                  0 2023-06-11 10:56:48.985350  \n",
      "2              0                  0 2023-06-11 10:57:06.317682  \n",
      "3              2                  0 2023-06-11 10:57:06.317682  \n",
      "4              5                  0 2023-06-11 10:57:06.317682  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cac7eabb897fb6",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4966cb216bfe6e29",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.685740500Z",
     "start_time": "2024-03-03T00:35:37.612736800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names are  Index(['id', 'conversation_id', 'flow_id', 'step_id', 'direction', 'payload',\n",
      "       'content_type', 'message_order', 'interaction_order', 'created_at'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"column names are \",df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74cfb1e8903d5e97",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.686250500Z",
     "start_time": "2024-03-03T00:35:37.626733900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column numbers are id                   20137\n",
      "conversation_id      20137\n",
      "flow_id              20137\n",
      "step_id              20137\n",
      "direction            20137\n",
      "payload              20137\n",
      "content_type         20137\n",
      "message_order        20137\n",
      "interaction_order    20137\n",
      "created_at           20137\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"column numbers are\",df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feaab143a47d847",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Transfer the dataset as a csv file \n",
    "we can check the dataset file directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7236fd15632a68c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.783293500Z",
     "start_time": "2024-03-03T00:35:37.643733600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the file path and name\n",
    "file_path = r\"C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\data\\verhaltensaktivierung.parquet.csv\"\n",
    "# Write DataFrame to CSV with UTF-8 encoding\n",
    "df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c92bc96aad37d66",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1 and 2: Filter\n",
    "This Python code uses pandas to filter a DataFrame df in two steps:\n",
    "1. Select rows where flow_id equals 'verhaltensaktivierung-2', because it contains the most important data that we want to use in the fine tuning.\n",
    "2. Further narrow down to rows where content_type is either 'text', 'question', or 'payload', as they are key components of prompt construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1c35233cc8d85a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.798804500Z",
     "start_time": "2024-03-03T00:35:37.784294600Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = df[df['flow_id'] == 'verhaltensaktivierung-2']\n",
    "\n",
    "filtered_df = filtered_df[filtered_df['content_type'].isin(['text', 'question', 'payload'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bccbae00cd07f9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.834812500Z",
     "start_time": "2024-03-03T00:35:37.799807500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                      id  \\\n59  b416224d-57f9-46b3-9fe2-8a4c3d5245c1   \n61  93988c30-1843-40f8-b6bf-790689a17b1e   \n63  89fa05bc-116d-4471-a3de-a2091026f7cd   \n64  a478b7d3-ab3d-484b-94b3-18d379838215   \n65  b2625dd7-2a92-4b5a-9c8f-576c79ceb85d   \n\n                         conversation_id                  flow_id step_id  \\\n59  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n61  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n63  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n64  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n65  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n\n   direction                                            payload content_type  \\\n59      SEND  {\"content\":{\"text\":\"Lass uns mal versuchen, ei...         text   \n61   RECEIVE  {\"content\":{\"payload\":\"👍\"},\"content_type\":\"pay...      payload   \n63   RECEIVE  {\"content\":{\"payload\":\"Geht eigentlich\"},\"cont...      payload   \n64      SEND  {\"content\":{\"text\":\"Aber da bist du nicht alle...         text   \n65      SEND  {\"content\":{\"text\":\"Aber: Positive Aktivitäten...         text   \n\n    message_order  interaction_order                 created_at  \n59              2                  0 2023-06-11 18:32:24.503132  \n61              0                  0 2023-06-11 18:32:35.093439  \n63              0                  0 2023-06-11 18:32:54.221356  \n64              2                  0 2023-06-11 18:32:54.221356  \n65              5                  0 2023-06-11 18:32:54.221356  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>conversation_id</th>\n      <th>flow_id</th>\n      <th>step_id</th>\n      <th>direction</th>\n      <th>payload</th>\n      <th>content_type</th>\n      <th>message_order</th>\n      <th>interaction_order</th>\n      <th>created_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>59</th>\n      <td>b416224d-57f9-46b3-9fe2-8a4c3d5245c1</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>SEND</td>\n      <td>{\"content\":{\"text\":\"Lass uns mal versuchen, ei...</td>\n      <td>text</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:24.503132</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>93988c30-1843-40f8-b6bf-790689a17b1e</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>RECEIVE</td>\n      <td>{\"content\":{\"payload\":\"👍\"},\"content_type\":\"pay...</td>\n      <td>payload</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:35.093439</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>89fa05bc-116d-4471-a3de-a2091026f7cd</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>RECEIVE</td>\n      <td>{\"content\":{\"payload\":\"Geht eigentlich\"},\"cont...</td>\n      <td>payload</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:54.221356</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>a478b7d3-ab3d-484b-94b3-18d379838215</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>SEND</td>\n      <td>{\"content\":{\"text\":\"Aber da bist du nicht alle...</td>\n      <td>text</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:54.221356</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>b2625dd7-2a92-4b5a-9c8f-576c79ceb85d</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>SEND</td>\n      <td>{\"content\":{\"text\":\"Aber: Positive Aktivitäten...</td>\n      <td>text</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:54.221356</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18625779408a67ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Selected Dataset Generation\n",
    "All downstream tasks based on this dataset: sorted_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d4a9c7b96a31fb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.909450300Z",
     "start_time": "2024-03-03T00:35:37.823804400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                      id  \\\n59  b416224d-57f9-46b3-9fe2-8a4c3d5245c1   \n61  93988c30-1843-40f8-b6bf-790689a17b1e   \n68  362cd471-2cb8-4a8b-95cc-48c60cbf971b   \n63  89fa05bc-116d-4471-a3de-a2091026f7cd   \n64  a478b7d3-ab3d-484b-94b3-18d379838215   \n\n                         conversation_id                  flow_id step_id  \\\n59  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n61  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n68  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n63  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n64  fb0749b3-3391-4f35-9ad6-958a1b9a931c  verhaltensaktivierung-2   start   \n\n   direction                                            payload content_type  \\\n59      SEND  {\"content\":{\"text\":\"Lass uns mal versuchen, ei...         text   \n61   RECEIVE  {\"content\":{\"payload\":\"👍\"},\"content_type\":\"pay...      payload   \n68      SEND  {\"content\":{\"buttons\":[{\"content\":{\"accepts\":[...     question   \n63   RECEIVE  {\"content\":{\"payload\":\"Geht eigentlich\"},\"cont...      payload   \n64      SEND  {\"content\":{\"text\":\"Aber da bist du nicht alle...         text   \n\n    message_order  interaction_order                 created_at  \n59              2                  0 2023-06-11 18:32:24.503132  \n61              0                  0 2023-06-11 18:32:35.093439  \n68              2                  0 2023-06-11 18:32:35.093439  \n63              0                  0 2023-06-11 18:32:54.221356  \n64              2                  0 2023-06-11 18:32:54.221356  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>conversation_id</th>\n      <th>flow_id</th>\n      <th>step_id</th>\n      <th>direction</th>\n      <th>payload</th>\n      <th>content_type</th>\n      <th>message_order</th>\n      <th>interaction_order</th>\n      <th>created_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>59</th>\n      <td>b416224d-57f9-46b3-9fe2-8a4c3d5245c1</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>SEND</td>\n      <td>{\"content\":{\"text\":\"Lass uns mal versuchen, ei...</td>\n      <td>text</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:24.503132</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>93988c30-1843-40f8-b6bf-790689a17b1e</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>RECEIVE</td>\n      <td>{\"content\":{\"payload\":\"👍\"},\"content_type\":\"pay...</td>\n      <td>payload</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:35.093439</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>362cd471-2cb8-4a8b-95cc-48c60cbf971b</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>SEND</td>\n      <td>{\"content\":{\"buttons\":[{\"content\":{\"accepts\":[...</td>\n      <td>question</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:35.093439</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>89fa05bc-116d-4471-a3de-a2091026f7cd</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>RECEIVE</td>\n      <td>{\"content\":{\"payload\":\"Geht eigentlich\"},\"cont...</td>\n      <td>payload</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:54.221356</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>a478b7d3-ab3d-484b-94b3-18d379838215</td>\n      <td>fb0749b3-3391-4f35-9ad6-958a1b9a931c</td>\n      <td>verhaltensaktivierung-2</td>\n      <td>start</td>\n      <td>SEND</td>\n      <td>{\"content\":{\"text\":\"Aber da bist du nicht alle...</td>\n      <td>text</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2023-06-11 18:32:54.221356</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['created_at'] = pd.to_datetime(filtered_df['created_at'])\n",
    "\n",
    "sorted_df = filtered_df.sort_values(by='created_at')\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "136dc66781edeac1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.984442400Z",
     "start_time": "2024-03-03T00:35:37.848805700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "59    {\"content\":{\"text\":\"Lass uns mal versuchen, ei...\n61    {\"content\":{\"payload\":\"👍\"},\"content_type\":\"pay...\n68    {\"content\":{\"buttons\":[{\"content\":{\"accepts\":[...\n63    {\"content\":{\"payload\":\"Geht eigentlich\"},\"cont...\n64    {\"content\":{\"text\":\"Aber da bist du nicht alle...\nName: payload, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.payload.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fffd5f41900f7f2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:37.986981800Z",
     "start_time": "2024-03-03T00:35:37.863844800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_df count:  8991\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted_df count: \", len(sorted_df),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d2882f92663f12",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:38.019015900Z",
     "start_time": "2024-03-03T00:35:37.878884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique conversation_id 119\n"
     ]
    }
   ],
   "source": [
    "print(\"unique conversation_id\",len(sorted_df['conversation_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a649a5181029a117",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 3: JSONL Transformation\n",
    "Transfer the selected dataset to extract conversations into a format that can be used by the LLM as OpenAI has provided a JSONL example:\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n",
    "Source: https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d83f5fa3fd8c8a27",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:38.199059300Z",
     "start_time": "2024-03-03T00:35:37.898421100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Li\\\\Desktop\\\\Engineering Seminar Human-Centered Systems\\\\data\\\\converted_messages.jsonl'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "role_mapping = {'SEND': 'assistant', 'RECEIVE': 'user'}\n",
    "sorted_df['role'] = sorted_df['direction'].map(role_mapping)\n",
    "\n",
    "# Function to extract content from payload\n",
    "def extract_content(payload):\n",
    "    try:\n",
    "        payload_json = json.loads(payload)\n",
    "        if 'content' in payload_json and 'title' in payload_json['content']:\n",
    "            return payload_json['content']['title']\n",
    "        if 'payload' in payload_json['content']:\n",
    "            return payload_json['content']['payload']\n",
    "        elif 'text' in payload_json['content']:\n",
    "            return payload_json['content']['text']\n",
    "    except json.JSONDecodeError:\n",
    "        return payload\n",
    "    return 'Content cannot be extracted'\n",
    "\n",
    "#Apply this function to the payload column\n",
    "sorted_df['content'] = sorted_df['payload'].apply(extract_content)\n",
    "\n",
    "# Function for converting a single conversation to JSON\n",
    "def conversation_to_json(group):\n",
    "    # Add fixed system message\n",
    "    system_message = {\"role\": \"system\", \"content\": \"You are a helpful chatbot that based on Behavioural activation treatment.\"}\n",
    "    messages = [system_message] + group[['role', 'content']].to_dict(orient='records')\n",
    "    return {'messages': messages}\n",
    "\n",
    "# Group by conversation_id and transform each group\n",
    "conversations_json = sorted_df.groupby('conversation_id').apply(conversation_to_json)\n",
    "\n",
    "#Specify the path to save the JSONL file\n",
    "output_file_path = r\"C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\data\\converted_messages.jsonl\"\n",
    "\n",
    "# Write each conversation to a JSONL file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for conversation in conversations_json:\n",
    "        json.dump(conversation, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "output_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f9612989008d3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step4: Data analysis for chat model fine-tuning\n",
    "Supported by Data preparation and analysis for chat model fine-tuning: https://cookbook.openai.com/examples/chat_finetuning_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a4ccc04920f3da",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:38.271086Z",
     "start_time": "2024-03-03T00:35:38.094536200Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421b0cc4d02cb0a6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:38.306712600Z",
     "start_time": "2024-03-03T00:35:38.206059800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 119\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a helpful chatbot that based on Behavioural activation treatment.'}\n",
      "{'role': 'assistant', 'content': 'Lass uns mal versuchen, ein paar Aktivitäten zu finden, die dir Spaß machen! 🙌'}\n",
      "{'role': 'user', 'content': '👍'}\n",
      "{'role': 'assistant', 'content': 'Fällt es dir schwer, eine positive Aktivität in deinen Alltag einzubauen?'}\n",
      "{'role': 'user', 'content': 'Geht eigentlich'}\n",
      "{'role': 'assistant', 'content': 'Aber da bist du nicht allein! Viele haben genug für die Schule, Universität oder Arbeit 🧑💼 zu tun und nur wenig Freizeit.'}\n",
      "{'role': 'assistant', 'content': 'Aber: Positive Aktivitäten müssen keine große Sache sein!'}\n",
      "{'role': 'assistant', 'content': 'Manchmal kann es schon helfen, wenn du duschen gehst und dich danach frisch fühlst. 🚿'}\n",
      "{'role': 'assistant', 'content': 'Auch solche kleinen Aktivitäten können helfen, deine Stimmung zu verbessern und auf bessere Gedanken zu kommen.'}\n",
      "{'role': 'user', 'content': 'Ich verstehe. 👌'}\n",
      "{'role': 'assistant', 'content': 'Bestimmt kennst du ein paar Aktivitäten, bei denen du sagst, ...'}\n",
      "{'role': 'assistant', 'content': '... das macht mir Spaß. 🎈 Dabei habe ich gute Laune. Dabei kann ich mich entspannen. 💆'}\n",
      "{'role': 'assistant', 'content': 'Fällt dir was ein oder soll ich dir Beispiele zeigen?'}\n",
      "{'role': 'assistant', 'content': 'Lass uns doch mal 3 Aktivitäten sammeln, die dir im Alltag Freude machen könnten. Okay?'}\n",
      "{'role': 'assistant', 'content': 'Was mach dir im Alltag Freude? Was ist die erste Aktivität, die dir einfällt?'}\n",
      "{'role': 'user', 'content': 'Ich weiß was, lass uns starten!'}\n",
      "{'role': 'assistant', 'content': 'Super! Dann los! 🚀'}\n",
      "{'role': 'user', 'content': 'Sport'}\n",
      "{'role': 'assistant', 'content': 'Danke. Und was ist die Zweite?'}\n",
      "{'role': 'user', 'content': 'Freunde treffen'}\n",
      "{'role': 'assistant', 'content': '👍 Hast du noch eine dritte Aktivität für mich?'}\n",
      "{'role': 'user', 'content': 'Kochen'}\n",
      "{'role': 'assistant', 'content': 'Wohoo! 🥳 Geschafft! Jetzt haben wir 3 Aktivitäten, die dir Freude machen.'}\n",
      "{'role': 'assistant', 'content': 'Denke daran: Nur wenn du etwas machst, dann wird es dir langsam besser gehen!'}\n",
      "{'role': 'assistant', 'content': 'Damit du die schönen Aktivitäten auch wirklich umsetzt, planen wir die jetzt einfach gemeinsam!'}\n",
      "{'role': 'assistant', 'content': 'Kennst du das auch von dir?'}\n",
      "{'role': 'assistant', 'content': 'Etwas zu planen ergibt Sinn, da viele junge Menschen gestresst sind.'}\n",
      "{'role': 'user', 'content': 'Okay 👍'}\n",
      "{'role': 'assistant', 'content': 'Denn du hast was, auf das du dich freuen kannst. 🎉'}\n",
      "{'role': 'user', 'content': 'Ja, das kenne ich'}\n",
      "{'role': 'assistant', 'content': 'Wenn du nämlich positive Aktivitäten planst, bist du gleich etwas entspannter!'}\n",
      "{'role': 'assistant', 'content': 'Pass dabei aber auf andere Termine auf. Die können wir ja nicht verändern. 📅'}\n",
      "{'role': 'assistant', 'content': 'An sehr stressigen Tagen können die schönen Aktivitäten auch kurz sein: So zwischen 30 Sekunden und 15 Minuten.'}\n",
      "{'role': 'user', 'content': '👌 Klingt gut.'}\n",
      "{'role': 'assistant', 'content': 'Lass uns das mal ausprobieren! Wir planen mal Aktivitäten, die dir Spaß machen!'}\n",
      "{'role': 'assistant', 'content': 'Du musst dir für die schönen Aktivitäten einen echten Termin machen, dann ist es gleich viel einfacher...'}\n",
      "{'role': 'assistant', 'content': 'Okay?'}\n",
      "{'role': 'assistant', 'content': 'Merke dir: Du musst wissen, 1. was du machen willst und 2. wann du es machen willst.'}\n",
      "{'role': 'user', 'content': 'Okay'}\n",
      "{'role': 'user', 'content': '👍'}\n",
      "{'role': 'assistant', 'content': 'Erinnere dich nochmal an die 3 Aktivitäten, die du vorhin genannt hast: 1. Sport, 2. Freunde treffen und 3. Kochen.'}\n",
      "{'role': 'assistant', 'content': 'Welche der 3 möchtest du am liebsten mit mir planen?'}\n",
      "{'role': 'assistant', 'content': 'Eine Aktivität davon würde ich gerne genau mit dir planen. Eine reicht erstmal.'}\n",
      "{'role': 'user', 'content': 'Sport'}\n",
      "{'role': 'assistant', 'content': 'Super! Jetzt wissen wir: WAS du machen willst.'}\n",
      "{'role': 'assistant', 'content': 'Dann lass uns schauen WANN!'}\n",
      "{'role': 'assistant', 'content': 'Wie viel Zeit ungefähr brauchst du für diese Aktivität? Falls du dafür irgendwo hinfahren musst, plane auch An- und Abfahrt ein!'}\n",
      "{'role': 'assistant', 'content': 'Okay, wie lange brauchst du?'}\n",
      "{'role': 'assistant', 'content': 'Wann passt es für dich? An welchem Tag und zu welcher Uhrzeit?'}\n",
      "{'role': 'assistant', 'content': 'An welchem Tag hast du denn ausreichend Zeit, dass du diese Aktivität machen kannst? 📅'}\n",
      "{'role': 'user', 'content': '2 h'}\n",
      "{'role': 'user', 'content': 'Dienstag 10:00'}\n",
      "{'role': 'assistant', 'content': 'Perfekt!'}\n",
      "{'role': 'assistant', 'content': 'Jetzt haben wir: 1. WAS du machen willst, 2. WANN du es machen willst.'}\n",
      "{'role': 'assistant', 'content': 'Eine Sache muss ich aber noch unbedingt von dir wissen! 🙄'}\n",
      "{'role': 'user', 'content': '👍😎'}\n",
      "{'role': 'user', 'content': 'Welche denn?'}\n",
      "{'role': 'assistant', 'content': 'Was könnte dich davon abhalten, die Aktivität zu machen? Also obwohl du es ja fest geplant hast!'}\n",
      "{'role': 'assistant', 'content': 'Oft hilft es, wenn du dir vorher überlegst, was dazwischen kommen könnte. Damit du vorbereitet bist, wenn das wirklich passiert.'}\n",
      "{'role': 'assistant', 'content': 'Und, was könnte bei dir dazwischen kommen?'}\n",
      "{'role': 'user', 'content': 'Nichts eigentlich wenn ich es mir fest vornehme'}\n",
      "{'role': 'assistant', 'content': 'Verstehe!'}\n",
      "{'role': 'assistant', 'content': 'Und wie kannst du verhindern, dass du von deiner Aktivität abgehalten wirst? 💡 Tipp: Erinnerungen im Kalender oder Unterstützung durch Freunde können auch helfen.'}\n",
      "{'role': 'assistant', 'content': 'Lass mich das noch mal zusammenfassen, okay?'}\n",
      "{'role': 'user', 'content': 'Ok'}\n",
      "{'role': 'assistant', 'content': 'Sehr gut! Jetzt haben wir schon mal einen Plan. 👍'}\n",
      "{'role': 'user', 'content': 'Gern!'}\n",
      "{'role': 'assistant', 'content': 'Wenn du etwas Schönes machen möchtest, gehst du so vor:'}\n",
      "{'role': 'assistant', 'content': '1. Überlege, WAS du machen willst! 2. Überlege, WANN du es machen willst! 3. Trage es dir als Termin in deinen Kalender ein!'}\n",
      "{'role': 'assistant', 'content': 'und'}\n",
      "{'role': 'assistant', 'content': '4. Überlege, was dich davon ABHALTEN könnte! 5. Und, was du DAGEGEN tun kannst.'}\n",
      "{'role': 'assistant', 'content': 'In diesen Schritten kannst du es ab jetzt immer angehen. Das hilft dir, die schönen Aktivitäten auch wirklich zu machen.'}\n",
      "{'role': 'assistant', 'content': 'Versuch in den nächsten Tagen mal, diese Methode anzuwenden. 🙏'}\n",
      "{'role': 'user', 'content': '👍'}\n",
      "{'role': 'assistant', 'content': 'Okay, das war doch schon mal sehr gut! Ich bin stolz auf dich! 🤩'}\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\data\\converted_messages.jsonl\" \n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7bcab3e115275bd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:38.309719500Z",
     "start_time": "2024-03-03T00:35:38.237062100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "# Add a list to record the index of the wrong example\n",
    "missing_assistant_examples = []\n",
    "\n",
    "for i, ex in enumerate(dataset):\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "        missing_assistant_examples.append(i)  # 记录发生错误的例子的索引\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    if missing_assistant_examples:\n",
    "        print(\"Missing assistant messages in examples:\", missing_assistant_examples)\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c768488b4496626",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:38.685463800Z",
     "start_time": "2024-03-03T00:35:38.268084200Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b6a7828dc50bcdd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:38.947270700Z",
     "start_time": "2024-03-03T00:35:38.687980900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 1\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 2, 83\n",
      "mean / median: 76.5546218487395, 75.0\n",
      "p5 / p95: 75.0, 83.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 50, 1790\n",
      "mean / median: 1565.2689075630253, 1548.0\n",
      "p5 / p95: 1508.8, 1707.4\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 25, 1261\n",
      "mean / median: 1142.5126050420167, 1120.0\n",
      "p5 / p95: 1109.0, 1247.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d68cc1ab877434f0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:38.995874400Z",
     "start_time": "2024-03-03T00:35:38.948268800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~186267 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~558801 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 5:Remove examples that violate OpenAI content policies, when we push data into a fine-tuned model.\n",
    "\n",
    "See 5.Fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30ef2c599fd09e05"
  },
  {
   "cell_type": "markdown",
   "id": "764f65f3d78f7521",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.Design Chatbot\n",
    "Behavioral Activation is a method for a psychical therapy by:\n",
    "Taking part in psychologically beneficial activities,\n",
    "Keeping away from psychologically harmful activities and \n",
    "Solving mechanisms problems that hinder access to rewards or enhance negative control.\n",
    "\n",
    "### What should Chatbot do? \n",
    " 1.BA Introduction: Explain BA understandably at first and chatbot makes a self-introduction.\n",
    " 2.Mood Track: Ask user’s emotion today.\n",
    " 3.Activity Recommendation: Find activities that user likes and encourage the user to take part in them.\n",
    " 4.Activity Management : Schedule (PST or ICS files if possible) the activities and check in.\n",
    " 5.Incentive mechanism: prevent users from not doing the activity.\n",
    "    1).Public Declaration: encourage users to share their goals and activities publicly, such as on twitter. The social pressure and potential for public accountability can be a strong incentive.\n",
    "    2).Partner Supervision: encourage users to share their goals and activities to their friends and family so that they can supervise users’ activities and try to prevent users from avoiding participating in activities.\n",
    "    3).Schedule Check-in history: remind users to check their finished und uncompleted schedule.\n",
    "    4).Compliment and Praises: encourage users when they complete activities and remind users to remember and share the joy of successful completion of schedules.\n",
    "  \n",
    "### Knowledge Hub loading\n",
    "Knowledge Hub contains relevant knowledge of BA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ecb6f61db5fc7be",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:38.999879300Z",
     "start_time": "2024-03-03T00:35:38.962272400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   entities                                       descriptions\n0                     Zest    Great enthusiasm and energy, often marked by ...\n1                   Zenith    A feeling of being at the peak or highest poi...\n2                 Yearning    A deep longing, especially for something or s...\n3                   Wonder    A feeling of amazement and admiration, caused...\n4              Wistfulness    A feeling of vague or regretful longing, ofte...\n..                      ...                                                ...\n95          BA Introduction   Explain BA understandably at first and chatbo...\n96  Activity Recommendation   Find activities that user likes and encourage...\n97            add schedule                                     add an activity\n98            get schedule                                     get an activity\n99         delete schedule                                  delete an activity\n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entities</th>\n      <th>descriptions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Zest</td>\n      <td>Great enthusiasm and energy, often marked by ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Zenith</td>\n      <td>A feeling of being at the peak or highest poi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Yearning</td>\n      <td>A deep longing, especially for something or s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wonder</td>\n      <td>A feeling of amazement and admiration, caused...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wistfulness</td>\n      <td>A feeling of vague or regretful longing, ofte...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>BA Introduction</td>\n      <td>Explain BA understandably at first and chatbo...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Activity Recommendation</td>\n      <td>Find activities that user likes and encourage...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>add schedule</td>\n      <td>add an activity</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>get schedule</td>\n      <td>get an activity</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>delete schedule</td>\n      <td>delete an activity</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\data\\knowledge.csv'\n",
    "knowledge_df = pd.read_csv(file_path, sep='\\\\|\\\\|', engine='python',encoding='UTF-8')\n",
    "knowledge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac53e95e7239700",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Schedule List loading\n",
    "User Information such as Schedule and User Mood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9868f2044cbab18f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:39.067885Z",
     "start_time": "2024-03-03T00:35:38.977300800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [event_id, summary, start_date_time, end_date_time, time_zone, location, status, attendees, creation_date, last_modified_date, reminders]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_id</th>\n      <th>summary</th>\n      <th>start_date_time</th>\n      <th>end_date_time</th>\n      <th>time_zone</th>\n      <th>location</th>\n      <th>status</th>\n      <th>attendees</th>\n      <th>creation_date</th>\n      <th>last_modified_date</th>\n      <th>reminders</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\data\\calendar.csv'\n",
    "schedule_df = pd.read_csv(file_path, sep='\\\\|\\\\|', engine='python',encoding='UTF-8')\n",
    "schedule_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa087af9add502",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Basis Functions for the Knowledge Hub: sort_dataframe,add_sort_entity,delete_matching_entity,search_description,update_entity_description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b55959262be5c8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:39.095509100Z",
     "start_time": "2024-03-03T00:35:38.993874400Z"
    }
   },
   "outputs": [],
   "source": [
    "def sort_dataframe(df):\n",
    "    # Sort by the first word of entities column\n",
    "    df.sort_values(by='entities', key=lambda x: x.str.split().str[0], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ee6406cbdf7771b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:39.112509900Z",
     "start_time": "2024-03-03T00:35:39.012877600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   entities                                       descriptions\n64             \"Exuberance    The quality of being full of energy, exciteme...\n61             \"Foreboding    A feeling that something bad will happen; fea...\n49             \"Insecurity    A feeling of uncertainty or anxiety about one...\n29              \"Pessimism    A tendency to see the worst aspect of things ...\n96  Activity Recommendation   Find activities that user likes and encourage...\n..                      ...                                                ...\n1                   Zenith    A feeling of being at the peak or highest poi...\n0                     Zest    Great enthusiasm and energy, often marked by ...\n97            add schedule                                     add an activity\n99         delete schedule                                  delete an activity\n98            get schedule                                     get an activity\n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entities</th>\n      <th>descriptions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>64</th>\n      <td>\"Exuberance</td>\n      <td>The quality of being full of energy, exciteme...</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>\"Foreboding</td>\n      <td>A feeling that something bad will happen; fea...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>\"Insecurity</td>\n      <td>A feeling of uncertainty or anxiety about one...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>\"Pessimism</td>\n      <td>A tendency to see the worst aspect of things ...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Activity Recommendation</td>\n      <td>Find activities that user likes and encourage...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Zenith</td>\n      <td>A feeling of being at the peak or highest poi...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Zest</td>\n      <td>Great enthusiasm and energy, often marked by ...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>add schedule</td>\n      <td>add an activity</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>delete schedule</td>\n      <td>delete an activity</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>get schedule</td>\n      <td>get an activity</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "df = sort_dataframe(knowledge_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97fc9eb9cfd80914",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:39.165483100Z",
     "start_time": "2024-03-03T00:35:39.025892Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_sort_entity(df, new_entity, new_description):\n",
    "\n",
    "    new_row = pd.DataFrame({'entities': [new_entity], 'descriptions': [new_description]})\n",
    "    \n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df = sort_dataframe(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49dc546ab4e8e3f3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:39.167482500Z",
     "start_time": "2024-03-03T00:35:39.041885900Z"
    }
   },
   "outputs": [],
   "source": [
    "def delete_matching_entity(df, entity_to_delete):\n",
    "\n",
    "    index_to_delete = df[df['entities'] == entity_to_delete].index.min()\n",
    "\n",
    "    if pd.notna(index_to_delete):\n",
    "        df = df.drop(index_to_delete)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ea7f1f00392becb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:39.199110900Z",
     "start_time": "2024-03-03T00:35:39.054880800Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_description(df, entity_to_search):\n",
    "    # Remove extra spaces\n",
    "    cleaned_search = entity_to_search.strip()\n",
    "\n",
    "    # Use a more flexible matching method\n",
    "    matching_rows = df[df['entities'].str.contains(cleaned_search, case=False, na=False, regex=False)]\n",
    "\n",
    "    # Check if a matching line is found\n",
    "    if not matching_rows.empty:\n",
    "        # Return the description value of the first matching item\n",
    "        return matching_rows.iloc[0]['descriptions']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abc1958f74742e6a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:39.201122300Z",
     "start_time": "2024-03-03T00:35:39.070890700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Behavioral Activation is a method for a psychical therapy by: Taking part in psychologically beneficial activities, keeping away from psychologically harmful activities, and solving mechanisms problems that hinder access to rewards or enhance negative control.'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_description(df,\"Behavioral Activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd100919854fdfe9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:39.226124900Z",
     "start_time": "2024-03-03T00:35:39.086921Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_entity_description(df, original_entity, updated_entity, updated_description):\n",
    "    # Find lines matching original entity and description\n",
    "    for index, row in df.iterrows():\n",
    "        if row['entities'] == original_entity :\n",
    "            df.at[index, 'entities'] = updated_entity\n",
    "            df.at[index, 'descriptions'] = updated_description\n",
    "            break  # Assume only the first matching row is updated\n",
    "    else:\n",
    "        print(\"No matching row found to update\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b98585f73282f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Why we need RAG?\n",
    "1. Update data in real time  (Mood detection)\n",
    "2. Search support\n",
    "3. Generate more accurate answers instead of making up confusing answers\n",
    "4. decrease noice and reduce the impact of information overload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_embeddings(embeddings):\n",
    "    \"\"\"\n",
    "    Normalize the embedding vector so that it becomes a unit vector.\n",
    "    \"\"\"\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    return embeddings / norms\n",
    "\n",
    "def extract_knowledges_from_df(df: pd.DataFrame, question, similarity_threshold=0.1):\n",
    "    \"\"\"\n",
    "    A lookup using the entities column in a DataFrame returns a DataFrame containing the entities and descriptions columns for the entities most relevant to a single question.\n",
    "     Based on a specified similarity threshold.\n",
    "    \"\"\"\n",
    "    model_name='all-MiniLM-L6-v2'\n",
    "    # Make sure the entities column exists\n",
    "    if 'entities' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have an 'entities' column\")\n",
    "\n",
    "    # Make sure the descriptions column exists\n",
    "    if 'descriptions' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have a 'descriptions' column\")\n",
    "\n",
    "    #Initialize SentenceTransformer model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Get the value of entities column\n",
    "    entities = df['entities'].tolist()\n",
    "\n",
    "    # Calculate the embedding vector of the entity\n",
    "    entity_embeddings = model.encode(entities, convert_to_tensor=False)\n",
    "    entity_embeddings = normalize_embeddings(entity_embeddings)\n",
    "\n",
    "    # Create faiss index (use inner product to simulate cosine similarity)\n",
    "    index = faiss.IndexFlatIP(entity_embeddings.shape[1])\n",
    "    index.add(entity_embeddings)\n",
    "\n",
    "    # Calculate the embedding vector of the problem and normalize it\n",
    "    question_embedding = model.encode(question, convert_to_tensor=False)\n",
    "    question_embedding = normalize_embeddings(question_embedding.reshape(1, -1))\n",
    "\n",
    "    # Search for all entities whose similarity to the question is higher than the threshold\n",
    "    distances, indices = index.search(question_embedding, len(entities))\n",
    "\n",
    "    # Filter out entities whose similarity is greater than or equal to the threshold\n",
    "    filtered_indices = [index for index, distance in zip(indices[0], distances[0]) if distance >= similarity_threshold]\n",
    "\n",
    "     # Get and return the rows containing the top three entities with the highest similarity\n",
    "    top_indices = filtered_indices[:1]  \n",
    "    result_df = df.iloc[top_indices]\n",
    "\n",
    "    return result_df[['entities', 'descriptions']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:46.168531700Z",
     "start_time": "2024-03-03T00:35:39.101522300Z"
    }
   },
   "id": "4f7c219102324d16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Timestamp for Prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3e358f2d28e5911"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "def get_current_timestamp():\n",
    "    return dt.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:46.186535300Z",
     "start_time": "2024-03-03T00:35:46.171531700Z"
    }
   },
   "id": "7efd54e0d10d1d22"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "'2024-03-03T01:35:46'"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_timestamp()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:46.231565500Z",
     "start_time": "2024-03-03T00:35:46.183535500Z"
    }
   },
   "id": "7e288698ec16dd2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Schedule Management"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bf1249b723eb410"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Google Calendar \n",
    "support by official quickstart tool from Google Workspace\n",
    "test user: 2\n",
    "mesenlee123@gmail.com\n",
    "flo.kuhlmeier@gmail.com\t\t\n",
    "https://developers.google.com/calendar/api/quickstart/python?hl=en"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f13ca5d710f90940"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "def google_calendar_service():\n",
    "    creds = Credentials.from_authorized_user_file('token.json')\n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "    return service\n",
    "\n",
    "def get_user_email():\n",
    "    creds = Credentials.from_authorized_user_file('token.json')\n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "    user_info = service.calendarList().get(calendarId='primary').execute()\n",
    "    user_email = user_info['summary']\n",
    "    return user_email\n",
    "\n",
    "def is_valid_datetime(dt_str):\n",
    "    try:\n",
    "        datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_valid_email(email):\n",
    "    return re.match(r\"[^@]+@[^@]+\\.[^@]+\", email)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:46.461621700Z",
     "start_time": "2024-03-03T00:35:46.200563400Z"
    }
   },
   "id": "fca796b86ce382d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### add event to Google Calendar"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30f54b409aca068c"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def add_event(schedule_df):\n",
    "    event_info = {\n",
    "        'summary': input('Enter event summary: '),\n",
    "        'location': input('Enter event location: '),\n",
    "        'start': {\n",
    "            'dateTime': input('Enter start date and time (YYYY-MM-DDTHH:MM:SS),skip when now: '),\n",
    "            'timeZone': input('Enter start time zone (e.g., America/Los_Angeles), skip when Europe/Berlin: '),\n",
    "        },\n",
    "        'end': {\n",
    "            'dateTime': input('Enter end date and time (YYYY-MM-DDTHH:MM:SS),skip when now: '),\n",
    "            'timeZone': input('Enter end time zone (e.g., America/Los_Angeles),skip when Europe/Berlin: '),\n",
    "        },\n",
    "        'attendees': [],\n",
    "        'reminders': {\n",
    "            'useDefault': False,\n",
    "            'overrides': [\n",
    "                {'method': 'email', 'minutes': 24 * 60},\n",
    "                {'method': 'popup', 'minutes': 10},\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Validate inputs\n",
    "    if event_info['summary'] == '':\n",
    "        event_info['summary'] = 'new event'\n",
    "    if event_info['location'] == '':\n",
    "        event_info['location'] = 'KIT'\n",
    "    if event_info['start']['dateTime'] == '':\n",
    "        event_info['start']['dateTime'] = get_current_timestamp()\n",
    "    if event_info['end']['dateTime'] == '':\n",
    "        event_info['end']['dateTime'] = get_current_timestamp()\n",
    "    if event_info['start']['timeZone'] == '':\n",
    "        event_info['start']['timeZone'] = 'Europe/Berlin'\n",
    "    if event_info['end']['timeZone'] == '':\n",
    "        event_info['end']['timeZone'] = 'Europe/Berlin'\n",
    "    \n",
    "    if not is_valid_datetime(event_info['start']['dateTime']):\n",
    "        print(\"Invalid start date and time format.\")\n",
    "        return schedule_df, None\n",
    "\n",
    "    if not is_valid_datetime(event_info['end']['dateTime']):\n",
    "        print(\"Invalid end date and time format.\")\n",
    "        return schedule_df, None\n",
    "\n",
    "    attendee_emails = input('Enter attendees emails separated by comma (skip): ').split(',')\n",
    "    if attendee_emails == '':\n",
    "        user_email = get_user_email()\n",
    "        print(\"user_email: \",user_email)\n",
    "        attendee_emails = user_email\n",
    "        event_info['attendees'] = [user_email]\n",
    "    \n",
    "    for email in attendee_emails:\n",
    "        email = email.strip()\n",
    "            \n",
    "        if email and is_valid_email(email):\n",
    "            event_info['attendees'].append({'email': email})\n",
    "        if email != '' and not is_valid_email(email):\n",
    "            print(f\"Invalid email format: {email}\")\n",
    "            return schedule_df, None\n",
    "\n",
    "    try:\n",
    "        service = google_calendar_service()\n",
    "        event = service.events().insert(calendarId='primary', body=event_info).execute()\n",
    "    \n",
    "        # Update DataFrame with response from API\n",
    "        new_event = {\n",
    "            'event_id': [event['id']],\n",
    "            'summary': [event['summary']],\n",
    "            'start_date_time': [event['start']['dateTime']],\n",
    "            'end_date_time': [event['end']['dateTime']],\n",
    "            'time_zone': [event['start']['timeZone']],\n",
    "            'location': [event.get('location', '')],\n",
    "            'status': [event.get('status', '')],\n",
    "            'attendees': [', '.join([attendee['email'] for attendee in event.get('attendees', [])])],\n",
    "            'creation_date': [event['created']],\n",
    "            'last_modified_date': [event['updated']],\n",
    "            'reminders': [str(event['reminders']['overrides'])]\n",
    "        }\n",
    "        new_event_df = pd.DataFrame(new_event)\n",
    "    \n",
    "        # Ensure the columns in both DataFrames match\n",
    "        for column in new_event_df.columns:\n",
    "            if column not in schedule_df.columns:\n",
    "                schedule_df[column] = None\n",
    "        \n",
    "        schedule_df = pd.concat([schedule_df, new_event_df], ignore_index=True)\n",
    "        return schedule_df, event['id']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with the API call: {e}\")\n",
    "        return schedule_df, None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:46.483629700Z",
     "start_time": "2024-03-03T00:35:46.467622400Z"
    }
   },
   "id": "7668341faf948723"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def add_event_to_schedule(schedule_df):\n",
    "\n",
    "    schedule_df, event_id = add_event(schedule_df)\n",
    "    print(\"Event ID:\", event_id)\n",
    "    print(\"schedule_df:\", schedule_df)\n",
    "    return schedule_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:46.515766100Z",
     "start_time": "2024-03-03T00:35:46.480628200Z"
    }
   },
   "id": "dc9bc70a1a1ea12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### get event from Google Calendar"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a084cd0a50cf3f4c"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def get_event_with_eventId(eventId):#example = 'f5seohftfpg8kcmt6mlfdcti44'\n",
    "    creds = Credentials.from_authorized_user_file('token.json')\n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "    try:\n",
    "        instances = service.events().instances(calendarId='primary', eventId=eventId).execute()\n",
    "        return instances\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:46.518796800Z",
     "start_time": "2024-03-03T00:35:46.495733Z"
    }
   },
   "id": "def7bc55a386d5ca"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "{'kind': 'calendar#events',\n 'etag': '\"p33g9hvn6jra880o\"',\n 'summary': 'mesenlee123@gmail.com',\n 'description': '',\n 'updated': '2024-03-01T23:42:13.372Z',\n 'timeZone': 'Europe/Berlin',\n 'accessRole': 'owner',\n 'defaultReminders': [{'method': 'popup', 'minutes': 30}],\n 'nextSyncToken': 'COCY_uae1IQDEOCY_uae1IQDGAUg2tKJogIo2tKJogI=',\n 'items': []}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_event_with_eventId(\"f5seohftfpg8kcmt6mlfdcti44\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:46.970520900Z",
     "start_time": "2024-03-03T00:35:46.509765400Z"
    }
   },
   "id": "6362004dad9904ce"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "def delete_event_with_eventId(eventId, schedule_df):  # Example eventId = 'f5seohftfpg8kcmt6mlfdcti44'\n",
    "    creds = Credentials.from_authorized_user_file('token.json')\n",
    "    service = build('calendar', 'v3', credentials=creds)\n",
    "\n",
    "    try:\n",
    "        # Attempt to delete the event from Google Calendar\n",
    "        service.events().delete(calendarId='primary', eventId=eventId).execute()\n",
    "\n",
    "        # If the event is successfully deleted from Google Calendar, \n",
    "        # also remove it from the DataFrame\n",
    "        if eventId in schedule_df['event_id'].values:\n",
    "            schedule_df = schedule_df[schedule_df['event_id'] != eventId]\n",
    "            return schedule_df, f\"Event with ID {eventId} has been deleted from both Google Calendar and DataFrame.\"\n",
    "        else:\n",
    "            return schedule_df, f\"Event ID {eventId} not found in DataFrame but deleted from Google Calendar.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return schedule_df, f\"An error occurred: {e}\"\n",
    "\n",
    "# Example usage:\n",
    "# updated_df, message = delete_event_with_eventId('event_id_to_delete', schedule_df)\n",
    "# print(message)\n",
    "# print(updated_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:47.004039800Z",
     "start_time": "2024-03-03T00:35:46.974519900Z"
    }
   },
   "id": "67f167e52a74b56d"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(Empty DataFrame\n Columns: [event_id, summary, start_date_time, end_date_time, time_zone, location, status, attendees, creation_date, last_modified_date, reminders]\n Index: [],\n 'An error occurred: <HttpError 410 when requesting https://www.googleapis.com/calendar/v3/calendars/primary/events/ralsh9mrefmvb86o4f31lo3s08? returned \"Resource has been deleted\". Details: \"[{\\'domain\\': \\'global\\', \\'reason\\': \\'deleted\\', \\'message\\': \\'Resource has been deleted\\'}]\">')"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_event_with_eventId(\"ralsh9mrefmvb86o4f31lo3s08\",schedule_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:47.341733Z",
     "start_time": "2024-03-03T00:35:46.988527700Z"
    }
   },
   "id": "81768a1320fc32d4"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "def get_event_without_eventId(schedule_df, summary, location, startTime, endTime):\n",
    "    # Load the sentence transformer model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Create embeddings for the input parameters\n",
    "    input_embedding = model.encode(f\"{summary} {location} {startTime} {endTime}\", convert_to_tensor=True)\n",
    "\n",
    "    # Function to embed DataFrame row\n",
    "    def embed_row(row):\n",
    "        row_str = f\"{row['summary']} {row['location']} {row['start_date_time']} {row['end_date_time']}\"\n",
    "        return model.encode(row_str, convert_to_tensor=True)\n",
    "\n",
    "    # Compute embeddings for each row in the DataFrame\n",
    "    schedule_df['embedding'] = schedule_df.apply(embed_row, axis=1)\n",
    "\n",
    "    # Calculate cosine similarity and find the row with the highest similarity\n",
    "    highest_similarity = -1\n",
    "    closest_event_id = None\n",
    "    for index, row in schedule_df.iterrows():\n",
    "        row_embedding = row['embedding']\n",
    "        similarity = util.pytorch_cos_sim(input_embedding, row_embedding)[0][0].item()\n",
    "        print(f\"Event ID: {row['event_id']}, Similarity: {similarity}\")  # Debug print\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            closest_event_id = row['event_id']\n",
    "\n",
    "    if closest_event_id is None:\n",
    "        print(\"No closely matching event found.\")\n",
    "    return get_event_with_eventId(closest_event_id)\n",
    "\n",
    "# Example usage\n",
    "# closest_event_id = get_event_without_eventId(schedule_df, 'new event', 'KIT', '2024-01-31T21:20:21+01:00', '2024-01-31T21:20:21+01:00')\n",
    "# print(\"Closest Event ID:\", closest_event_id)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:47.372733600Z",
     "start_time": "2024-03-03T00:35:47.344736100Z"
    }
   },
   "id": "c042f84d285a7840"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "def delete_event_without_eventId(schedule_df, summary, location, startTime, endTime):\n",
    "    # Load the sentence transformer model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Create embeddings for the input parameters\n",
    "    input_embedding = model.encode(f\"{summary} {location} {startTime} {endTime}\", convert_to_tensor=True)\n",
    "\n",
    "    # Function to embed DataFrame row\n",
    "    def embed_row(row):\n",
    "        row_str = f\"{row['summary']} {row['location']} {row['start_date_time']} {row['end_date_time']}\"\n",
    "        return model.encode(row_str, convert_to_tensor=True)\n",
    "\n",
    "    # Compute embeddings for each row in the DataFrame\n",
    "    schedule_df['embedding'] = schedule_df.apply(embed_row, axis=1)\n",
    "\n",
    "    # Calculate cosine similarity and find the row with the highest similarity\n",
    "    highest_similarity = -1\n",
    "    closest_event_id = None\n",
    "    for index, row in schedule_df.iterrows():\n",
    "        row_embedding = row['embedding']\n",
    "        similarity = util.pytorch_cos_sim(input_embedding, row_embedding)[0][0].item()\n",
    "        print(f\"Event ID: {row['event_id']}, Similarity: {similarity}\")  # Debug print\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            closest_event_id = row['event_id']\n",
    "\n",
    "    if closest_event_id is None:\n",
    "        print(\"No closely matching event found.\")\n",
    "    return delete_event_with_eventId(closest_event_id,schedule_df)\n",
    "\n",
    "# Example usage\n",
    "# closest_event_id = get_event_without_eventId(schedule_df, 'new event', 'KIT', '2024-01-31T21:20:21+01:00', '2024-01-31T21:20:21+01:00')\n",
    "# print(\"Closest Event ID:\", closest_event_id)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:47.392777600Z",
     "start_time": "2024-03-03T00:35:47.362734400Z"
    }
   },
   "id": "20a93d3eb4d9fdae"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No closely matching event found.\n"
     ]
    },
    {
     "data": {
      "text/plain": "(Empty DataFrame\n Columns: [event_id, summary, start_date_time, end_date_time, time_zone, location, status, attendees, creation_date, last_modified_date, reminders, embedding]\n Index: [],\n 'An error occurred: Missing required parameter \"eventId\"')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_event_without_eventId(schedule_df,'new event','KIT','2024-01-31T21:20:21+01:00','2024-01-31T21:20:21+01:00')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:48.271712100Z",
     "start_time": "2024-03-03T00:35:47.374733800Z"
    }
   },
   "id": "34573d1c58116167"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transfer Dataframe to string to construct prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6aba703baa2634a"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def dataframe_to_string(df):\n",
    "    \"\"\"\n",
    "    Convert each row of the DataFrame to a string and add a period after the end of each row.\n",
    "    If the DataFrame is empty, return an empty string.\n",
    "    \"\"\"\n",
    "    # 检查DataFrame是否为空\n",
    "    if df.empty:\n",
    "        return ''\n",
    "\n",
    "    # 将DataFrame的每行转换为由空格分隔的字符串，并添加句号\n",
    "    lines = [' '.join(map(str, row)) + '.' for row in df.itertuples(index=False, name=None)]\n",
    "    \n",
    "    # 将所有行连接成一个单一的字符串\n",
    "    context = ' '.join(lines)\n",
    "    return \" Given retrievaled context: \" + context\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:48.291720100Z",
     "start_time": "2024-03-03T00:35:48.275713800Z"
    }
   },
   "id": "89ac057d908c5e3e"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "' Given retrievaled context: Activity Recommendation  Find activities that user likes and encourage the user to take part in them.'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_to_string(extract_knowledges_from_df(knowledge_df,\"what should I do today?\",0.1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:48.597773Z",
     "start_time": "2024-03-03T00:35:48.288719100Z"
    }
   },
   "id": "acb4558b217cb4e3"
  },
  {
   "cell_type": "markdown",
   "id": "8dcfe440e60e445f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Save messages to the specified folder\n",
    "folder_path = r\"folder_path\"\n",
    "example: save_messages_to_txt(messages, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bd253d02c170fb5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:48.642773Z",
     "start_time": "2024-03-03T00:35:48.599773600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "folder_path = r\"C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\"\n",
    "def save_messages_to_jsonl(messages, folder_path):\n",
    "    # Create a filename based on the current timestamp\n",
    "    timestamp = dt.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    filename = f\"{timestamp}.jsonl\"\n",
    "\n",
    "    # Make sure the folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    #Create full file path\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    # Save messages to JSONL file\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        for message in messages:\n",
    "            # 将字典转换为JSON字符串并写入文件\n",
    "            json_str = json.dumps(message)\n",
    "            file.write(json_str + '\\n')\n",
    "\n",
    "    print(f\"Messages saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6a1ee7e0a1a94",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Single Answered Method\n",
    "Use get_answer_with_single_question to modify other functions like: Mood track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fb0ce7674b1c32d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:49.188390500Z",
     "start_time": "2024-03-03T00:35:48.612775700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "\n",
    "def get_answer_with_single_question(df, question, similarity_threshold = 0.1):\n",
    "\n",
    "    # Extract relevant information as context\n",
    "    context = dataframe_to_string(extract_knowledges_from_df(df,question,similarity_threshold))\n",
    "\n",
    "    # Set OpenAI API key\n",
    "    api_key = os.environ.get('OPENAI_API_KEY')\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    # Initialize OpenAI client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Set up the model\n",
    "    model=\"gpt-3.5-turbo-1106\"\n",
    "\n",
    "    try:\n",
    "        messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Given context, answer in a noun or a phrase with noun.\"},\n",
    "                    # instruction\n",
    "                    {\"role\": \"user\", \"content\": question + \" \" + context}\n",
    "        ]\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        # Extract and return the answer\n",
    "        answer = response.choices[0].message.content\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the problem: {e}\")\n",
    "        return \"Unable to get answer\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67f5140e87d9af54",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.067147600Z",
     "start_time": "2024-03-03T00:35:49.188390500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'hobbies and interests'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_with_single_question(df,\"what should I do today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1c7a9559ff41b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Mood and Activity Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bd30e538a95671c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.082469500Z",
     "start_time": "2024-03-03T00:35:50.068146700Z"
    }
   },
   "outputs": [],
   "source": [
    "def mood_track(df, similarity_threshold = 0.1):\n",
    "    history = str(messages[-5:])\n",
    "    mood_track = get_answer_with_single_question(knowledge_df,\"what is user's emotion ? Answer in a noun. given chat history: \"+history,similarity_threshold)\n",
    "    #print(\"mode_track: \",mood_track)\n",
    "    timestamp = get_current_timestamp()#datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    full_entity = f\"user emotion {timestamp}\"\n",
    "    new_description = mood_track\n",
    "    # Add and sort the new entry\n",
    "    df = add_sort_entity(df, full_entity, new_description)\n",
    "    #print(\"entity: \",full_entity)\n",
    "    #print(\"description: \",new_description)\n",
    "    return full_entity + \", \" + new_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53097051cd6df498",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.126378300Z",
     "start_time": "2024-03-03T00:35:50.083474700Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataframe_to_entity(df):\n",
    "    \"\"\"\n",
    "    Convert each row of the DataFrame to a string and add a period after the end of each row.\n",
    "    \"\"\"\n",
    "    # Convert each row of the DataFrame to a string separated by spaces and add periods\n",
    "    lines = [' '.join(map(str, row)) + '.' for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "    # Concatenate all lines into a single string\n",
    "    entity =  ' '.join(lines)\n",
    "    return str(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def extract_activity_from_df(df: pd.DataFrame, question, similarity_threshold=0.1):\n",
    "    \"\"\"\n",
    "    A lookup using the entities column in a DataFrame returns a DataFrame containing the entities and descriptions columns for the entities most relevant to a single question.\n",
    "     Based on a specified similarity threshold.\n",
    "    \"\"\"\n",
    "    model_name='all-MiniLM-L6-v2'\n",
    "    # Make sure the entities column exists\n",
    "    if 'entities' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have an 'entities' column\")\n",
    "\n",
    "    # Make sure the descriptions column exists\n",
    "    if 'descriptions' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have a 'descriptions' column\")\n",
    "\n",
    "    # Initialize SentenceTransformer model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Get the value of entities column\n",
    "    entities = df['entities'].tolist()\n",
    "\n",
    "    # Compute the embedding vector of an entity\n",
    "    entity_embeddings = model.encode(entities, convert_to_tensor=False)\n",
    "    entity_embeddings = normalize_embeddings(entity_embeddings)\n",
    "\n",
    "    # Create faiss index (use inner product to simulate cosine similarity)\n",
    "    index = faiss.IndexFlatIP(entity_embeddings.shape[1])\n",
    "    index.add(entity_embeddings)\n",
    "\n",
    "    # Calculate the embedding vector of the problem and normalize it\n",
    "    question_embedding = model.encode(question, convert_to_tensor=False)\n",
    "    question_embedding = normalize_embeddings(question_embedding.reshape(1, -1))\n",
    "\n",
    "    # Search for all entities that are more similar to the question than a threshold\n",
    "    distances, indices = index.search(question_embedding, len(entities))\n",
    "\n",
    "    # Filter out entities whose similarity is greater than or equal to the threshold\n",
    "    filtered_indices = [index for index, distance in zip(indices[0], distances[0]) if distance >= similarity_threshold]\n",
    "\n",
    "     # Get and return the rows containing the top three entities with the highest similarity\n",
    "    top_indices = filtered_indices[:1]  # Select the index with the highest similarity\n",
    "    result_df = df.iloc[top_indices]\n",
    "    \n",
    "    return dataframe_to_entity(result_df[['entities']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.129379Z",
     "start_time": "2024-03-03T00:35:50.098380100Z"
    }
   },
   "id": "ef18c123f0ad16bd"
  },
  {
   "cell_type": "markdown",
   "id": "339d0b3c52d22d95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.Fine tunning\n",
    "### Step 5:removed examples that violate OpenAI content policies (Data Preprocessing)\n",
    "This documents how did I remove examples. You can skip it and go to the fine-tuned model\n",
    "Note:\n",
    "Use standard version removed examples that violate our content policies: messages.jsonl, file_object.id: file-MfSaHHIx7s75dywsofhSQIpc\n",
    "standard transfered version: converted_messages.jsonl, File ID: file-flA9y8B28JIGeZSq1nM8fPh9\n",
    "(The job failed due to an invalid training file. This file failed moderation safety checks. The OpenAI Moderation API identifies fine-tuning examples that violate our content policies. To fine tune on this data, please try removing the flagged lines and uploading the file again. Flagged lines: 1, 2, 8, 10, 13, 14, 16, 19, 21, 22, 25, 27, 32, 33, 37, 38, 43, 50, 51, 52, 53, 54, 61, 62, 63, 64, 67, 69, 70, 72, 74, 75, 76, 81, 85, 87, 90, 91, 92, 94, 95, 96, 98, 99, 100, 105, 106, 107, 110, 112, 115, 117)\n",
    "Given Test version:test_messages.jsonl, File ID: file-nSLhAXDwgLhFbA5OVnVqRuTi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The job failed due to an invalid training file. This file failed moderation safety checks. The OpenAI Moderation API identifies fine tuning examples that violate our content policies. To fine tune on this data, please try removing the flagged lines and uploading the file again. Flagged lines: 1, 2, 8, 10, 13, 14, 16, 19, 21, 22, 25, 27, 32, 33, 37, 38, 43, 50, 51, 52, 53, 54, 61, 62, 63, 64, 67, 69, 70, 72, 74, 75, 76, 81, 85, 87, 90, 91, 92, 94, 95, 96, 98, 99, 100, 105, 106, 107, 110, 112, 115, 117"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82f15a9fc7eef6cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The job failed due to an invalid training file. This file failed moderation safety checks. The OpenAI Moderation API identifies fine tuning examples that violate our content policies. To fine tune on this data, please try removing the flagged lines and uploading the file again. Flagged lines: 0, 5, 6, 8, 9, 11, 12, 14, 15, 19, 22, 26, 32, 38, 40, 41, 42, 43, 47, 50, 51, 53, 54, 55, 59, 61, 62, 64, 65"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37193326d1ec3ca2"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\ndef remove_lines_and_save(input_file_path, output_file_path, lines_to_remove):\\n    \\n    with open(input_file_path, 'r', encoding='utf-8') as file:\\n        lines = file.readlines()\\n\\n\\n    lines_to_remove = [line - 1 for line in lines_to_remove]\\n    lines = [line for index, line in enumerate(lines) if index not in lines_to_remove]\\n\\n    with open(output_file_path, 'w', encoding='utf-8') as file:\\n        file.writelines(lines)\\n\""
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def remove_lines_and_save(input_file_path, output_file_path, lines_to_remove):\n",
    "    \n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "\n",
    "    lines_to_remove = [line - 1 for line in lines_to_remove]\n",
    "    lines = [line for index, line in enumerate(lines) if index not in lines_to_remove]\n",
    "\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(lines)\n",
    "\"\"\"\n",
    "# open when you want to upload new data for fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.172967500Z",
     "start_time": "2024-03-03T00:35:50.114380500Z"
    }
   },
   "id": "9efcab31d903b151"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "input_file = r'C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\data\\converted_messages.jsonl'  \n",
    "output_file = r'C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\data\\messages.jsonl' "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.187971300Z",
     "start_time": "2024-03-03T00:35:50.130381100Z"
    }
   },
   "id": "85dfb2146b74f1b1"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n \\nlines_to_remove = [1, 2, 8, 10, 13, 14, 16, 19, 21, 22, 25, 27, 32, 33, 37, 38, 43, 50, 51, 52, 53, 54, 61, 62, 63, 64, 67, 69, 70, 72, 74, 75, 76, 81, 85, 87, 90, 91, 92, 94, 95, 96, 98, 99, 100, 105, 106, 107, 110, 112, 115, 117]\\n\\nremove_lines_and_save(input_file, output_file, lines_to_remove)\\n'"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " \n",
    "lines_to_remove = [1, 2, 8, 10, 13, 14, 16, 19, 21, 22, 25, 27, 32, 33, 37, 38, 43, 50, 51, 52, 53, 54, 61, 62, 63, 64, 67, 69, 70, 72, 74, 75, 76, 81, 85, 87, 90, 91, 92, 94, 95, 96, 98, 99, 100, 105, 106, 107, 110, 112, 115, 117]\n",
    "\n",
    "remove_lines_and_save(input_file, output_file, lines_to_remove)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.190970900Z",
     "start_time": "2024-03-03T00:35:50.145379900Z"
    }
   },
   "id": "3dcbd44de43ed19f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The job failed due to an invalid training file. This file failed moderation safety checks. The OpenAI Moderation API identifies fine tuning examples that violate our content policies. To fine tune on this data, please try removing the flagged lines and uploading the file again. Flagged lines: 0, 5, 6, 8, 9, 11, 12, 14, 15, 19, 22, 26, 32, 38, 40, 41, 42, 43, 47, 50, 51, 53, 54, 55, 59, 61, 62, 64, 65"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17a9d5dbc4eb7ad"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\nlines_to_remove = [0, 5, 6, 8, 9, 11, 12, 14, 15, 19, 22, 26, 32, 38, 40, 41, 42, 43, 47, 50, 51, 53, 54, 55, 59, 61, 62, 64, 65]\\n\\nremove_lines_and_save(output_file, output_file, lines_to_remove)\\n\\n'"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "lines_to_remove = [0, 5, 6, 8, 9, 11, 12, 14, 15, 19, 22, 26, 32, 38, 40, 41, 42, 43, 47, 50, 51, 53, 54, 55, 59, 61, 62, 64, 65]\n",
    "\n",
    "remove_lines_and_save(output_file, output_file, lines_to_remove)\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.265534700Z",
     "start_time": "2024-03-03T00:35:50.160964900Z"
    }
   },
   "id": "e13f1a6cb3e11e86"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The job failed due to an invalid training file. This file failed moderation safety checks. The OpenAI Moderation API identifies fine tuning examples that violate our content policies. To fine tune on this data, please try removing the flagged lines and uploading the file again. Flagged lines: 0, 4, 5, 6, 7, 10, 12, 15, 20, 25, 26, 29, 31, 32, 35, 36, 37"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "206d0b95b92ff061"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nlines_to_remove = [0, 4, 5, 6, 7, 10, 12, 15, 20, 25, 26, 29, 31, 32, 35, 36, 37]\\n\\nremove_lines_and_save(output_file, output_file, lines_to_remove)\\n'"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lines_to_remove = [0, 4, 5, 6, 7, 10, 12, 15, 20, 25, 26, 29, 31, 32, 35, 36, 37]\n",
    "\n",
    "remove_lines_and_save(output_file, output_file, lines_to_remove)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.283539700Z",
     "start_time": "2024-03-03T00:35:50.176965100Z"
    }
   },
   "id": "7f68f65f788d5215"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The job failed due to an invalid training file. This file failed moderation safety checks. The OpenAI Moderation API identifies fine tuning examples that violate our content policies. To fine tune on this data, please try removing the flagged lines and uploading the file again. Flagged lines: 0, 3, 5, 6, 8, 12, 16, 18, 19, 21"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "569056bd7aec62df"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nlines_to_remove = [0, 3, 5, 6, 8, 12, 16, 18, 19, 21]\\n\\nremove_lines_and_save(output_file, output_file, lines_to_remove)\\n'"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lines_to_remove = [0, 3, 5, 6, 8, 12, 16, 18, 19, 21]\n",
    "\n",
    "remove_lines_and_save(output_file, output_file, lines_to_remove)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.298068100Z",
     "start_time": "2024-03-03T00:35:50.191972200Z"
    }
   },
   "id": "491e5fbdc3d80cf0"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\data\\messages.jsonl\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.301067100Z",
     "start_time": "2024-03-03T00:35:50.208533400Z"
    }
   },
   "id": "dc40c9d5f65ef564"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "541f62f429d903ac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.367066700Z",
     "start_time": "2024-03-03T00:35:50.222534400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n#\\nfrom openai import OpenAI\\nclient = OpenAI()\\n# use English version: converted_messages_en.jsonl\\nfile_object  = client.files.create(\\n  file=open(file_path, \"rb\"),# could be: #messages.jsonl,#converted_messages.jsonl,#test_messages.jsonl\\n  purpose=\"fine-tune\"\\n)\\nprint(\"file_object.id:\",file_object.id)\\nfile_object_id = file_object.id\\nfile_object \\n\\n'"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "# use English version: converted_messages_en.jsonl\n",
    "file_object  = client.files.create(\n",
    "  file=open(file_path, \"rb\"),# could be: #messages.jsonl,#converted_messages.jsonl,#test_messages.jsonl\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "print(\"file_object.id:\",file_object.id)\n",
    "file_object_id = file_object.id\n",
    "file_object \n",
    "\n",
    "'''\n",
    "# open when you want to upload new data for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "file_object_id = 'file-zDC09wFGIufN4eZaXd5FWFKv'#file-MI68lqdGDLIgx217LTbtFgzG\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.369065100Z",
     "start_time": "2024-03-03T00:35:50.239534200Z"
    }
   },
   "id": "377b544b0d43a84f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fine-tuning model\n",
    "fine_tuning_job\n",
    "fine_tuning_job.id=\"ftjob-YtoxfhaeCv5EDCjMt1PGbvHZ\" \n",
    "fine_tuned_model_name = \"gpt-3.5-turbo-0613\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8777b7623ef417fe"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7a64e4757f7cb30",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.389077Z",
     "start_time": "2024-03-03T00:35:50.254534600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# open when you want to upload new data for fine-tuning\\nfrom openai import OpenAI\\nclient = OpenAI()\\n\\nfine_tuning_job = client.fine_tuning.jobs.create(\\n  training_file = file_object_id, \\n  model=\"gpt-3.5-turbo\"\\n)\\nprint(fine_tuning_job.id)\\nfine_tuning_job\\n\\n#FineTuningJob(id=\\'ftjob-2Lpyr3aaKh1qmUa2PiqOr9ma\\', created_at=1704830407, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=\\'auto\\', batch_size=\\'auto\\', learning_rate_multiplier=\\'auto\\'), model=\\'gpt-3.5-turbo-0613\\', object=\\'fine_tuning.job\\', organization_id=\\'org-1RBrqOHK4MGbSBFmx0Tqvb1b\\', result_files=[], status=\\'validating_files\\', trained_tokens=None, training_file=\\'file-flA9y8B28JIGeZSq1nM8fPh9\\', validation_file=None)\\n'"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# open when you want to upload new data for fine-tuning\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "  training_file = file_object_id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "print(fine_tuning_job.id)\n",
    "fine_tuning_job\n",
    "\n",
    "#FineTuningJob(id='ftjob-2Lpyr3aaKh1qmUa2PiqOr9ma', created_at=1704830407, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-1RBrqOHK4MGbSBFmx0Tqvb1b', result_files=[], status='validating_files', trained_tokens=None, training_file='file-flA9y8B28JIGeZSq1nM8fPh9', validation_file=None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "fine_tuning_job_id = 'ftjob-YtoxfhaeCv5EDCjMt1PGbvHZ'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.404597400Z",
     "start_time": "2024-03-03T00:35:50.270533900Z"
    }
   },
   "id": "f521151700dc7168"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e14e315126fe756d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.422597200Z",
     "start_time": "2024-03-03T00:35:50.287538800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfrom openai import OpenAI\\nimport time\\n\\nclient = OpenAI()\\n\\n# Loop to check the status of the fine-tuning job\\nwhile True:\\n    fine_tuning_job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\\n    if fine_tuning_job.status == \\'succeeded\\':\\n        # The fine-tuning job is completed and the name of the fine-tuned model is obtained.\\n        fine_tuned_model_name = fine_tuning_job.fine_tuned_model\\n        print(\"finetunned model name:\", fine_tuned_model_name)\\n        break\\n    elif fine_tuning_job.status == \\'failed\\':\\n        print(\"Fine-tuning job failed.\")\\n        break\\n    print(\"Wait for the fine-tuning job to complete...\")\\n    time.sleep(60)\\n# open when you want to upload new data for fine-tuning\\n'"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Loop to check the status of the fine-tuning job\n",
    "while True:\n",
    "    fine_tuning_job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
    "    if fine_tuning_job.status == 'succeeded':\n",
    "        # The fine-tuning job is completed and the name of the fine-tuned model is obtained.\n",
    "        fine_tuned_model_name = fine_tuning_job.fine_tuned_model\n",
    "        print(\"finetunned model name:\", fine_tuned_model_name)\n",
    "        break\n",
    "    elif fine_tuning_job.status == 'failed':\n",
    "        print(\"Fine-tuning job failed.\")\n",
    "        break\n",
    "    print(\"Wait for the fine-tuning job to complete...\")\n",
    "    time.sleep(60)\n",
    "# open when you want to upload new data for fine-tuning\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "fine_tuned_model_name = 'ft:gpt-3.5-turbo-0613:personal::8fDseZ4U'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:35:50.435596500Z",
     "start_time": "2024-03-03T00:35:50.302068400Z"
    }
   },
   "id": "8030839c7916c696"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e14f9b2bca9c276",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T01:04:27.581436900Z",
     "start_time": "2024-03-03T00:53:08.029459900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm a chatbot for Behavioral Activation Therapy, focusing on positive activities and problem-solving. Talk to me about anything. 😊\n",
      "user_input 1: Can you give me an advice what activity should I take\n",
      "###############################\n",
      "context:   Given retrievaled context: Activity Recommendation  Find activities that user likes and encourage the user to take part in them.\n",
      "###############################\n",
      "Answer: Tell me, what are you interested in? 🙃\n",
      "###############################\n",
      "user_input 2: I like running and swimming\n",
      "###############################\n",
      "context:  \n",
      "###############################\n",
      "Answer: Sports and being outdoor are good activities to lift the mood. 🏃‍♂️💪\n",
      "###############################\n",
      "user_input 3: what is your suggestion?\n",
      "###############################\n",
      "context:   Given retrievaled context: Activity Recommendation  Find activities that user likes and encourage the user to take part in them.\n",
      "###############################\n",
      "Answer: How about doing some workout outside? You could go for a run or to the campus sports facilities. 🏋️‍♂️\n",
      "###############################\n",
      "user_input 4: I run\n",
      "###############################\n",
      "context:   Given retrievaled context: Defeat   A feeling of loss and disappointment, typically after losing a battle or failing to achieve something desired..\n",
      "###############################\n",
      "Answer: Great choice! This will get your endorphins flowing. 💕\n",
      "###############################\n",
      "user_input 5: add schedule\n",
      "###############################\n",
      "user_mood:  user emotion 2024-03-03T01:55:41, Enthusiasm\n",
      "###############################\n",
      "context:   Given retrievaled context: add schedule   add an activity.\n",
      "###############################\n",
      "Answer: Sure, I can help you with that. When do you want to do that?\n",
      "###############################\n",
      "Answer: Alright, I have put that in your calendar. 📅\n",
      "###############################\n",
      "user_input 6: get schedule\n",
      "###############################\n",
      "context:   Given retrievaled context: get schedule   get an activity.\n",
      "###############################\n",
      "Answer: You can find your schedule for today in your calendar.\n",
      "###############################\n",
      "Event ID: jejvdnu14l3fnvb4p262cteejo, Similarity: 0.5339872241020203\n",
      "Answer: Here is the schedule for today: You have running planned. 🏃‍♂️\n",
      "###############################\n",
      "user_input 7: delete schedule\n",
      "###############################\n",
      "context:   Given retrievaled context: delete schedule   delete an activity.\n",
      "###############################\n",
      "Answer: Sure, I can help you with that. What exactly do you want to delete?\n",
      "###############################\n",
      "Event ID: jejvdnu14l3fnvb4p262cteejo, Similarity: 0.33090123534202576\n",
      "Answer: Alright, I deleted the activity for you. 🗑\n",
      "###############################\n",
      "user_input 8: well done!!\n",
      "###############################\n",
      "context:  \n",
      "###############################\n",
      "Answer: Well done! You have completed the activity. I'm proud of you! 💪👍\n",
      "###############################\n",
      "Messages saved to C:\\Users\\Li\\Desktop\\Engineering Seminar Human-Centered Systems\\20240303020427.jsonl\n",
      "messages:  [{'role': 'system', 'content': 'You are a helpful chatbot that based on Behavioural activation treatment. Your answer must be less than 3 sentences. You used Google Calendar API so that user can use order to add event, get event and delete event. Add event order is add schedule. Get event order is get schedule. Delete event order is delete schedule. Find activities that user likes and encourage the user to take part in them. Encourage users to share their goals and activities publicly, such as on twitter. The social pressure and potential for public accountability can be a strong incentive. Encourage users to share their goals and activities to their friends and family so that they can supervise users’ activities and try to prevent users from avoiding participating in activities. Remind users to check their finished und uncompleted schedule. Encourage users when they complete activities and remind users to remember and share the joy of successful completion of schedules. If depression or anxiety is detected, chatbot need offer comforting words, suggestions, or techniques for emotion regulation. Given some context,you must give a suitable response based on the context.'}, {'role': 'assistant', 'content': \"Hi, I'm a chatbot for Behavioral Activation Therapy, focusing on positive activities and problem-solving. Talk to me about anything. 😊\"}, {'role': 'user', 'content': 'user_input: Can you give me an advice what activity should I take. user_input:  Given retrievaled context: Activity Recommendation  Find activities that user likes and encourage the user to take part in them.'}, {'role': 'assistant', 'content': 'Tell me, what are you interested in? 🙃'}, {'role': 'user', 'content': 'user_input: I like running and swimming. user_input: '}, {'role': 'assistant', 'content': 'Sports and being outdoor are good activities to lift the mood. 🏃\\u200d♂️💪'}, {'role': 'user', 'content': 'user_input: what is your suggestion?. user_input:  Given retrievaled context: Activity Recommendation  Find activities that user likes and encourage the user to take part in them.'}, {'role': 'assistant', 'content': 'How about doing some workout outside? You could go for a run or to the campus sports facilities. 🏋️\\u200d♂️'}, {'role': 'user', 'content': 'user_input: I run. user_input:  Given retrievaled context: Defeat   A feeling of loss and disappointment, typically after losing a battle or failing to achieve something desired..'}, {'role': 'assistant', 'content': 'Great choice! This will get your endorphins flowing. 💕'}, {'role': 'user', 'content': 'user_input: add schedule. user_input:  Given retrievaled context: add schedule   add an activity.'}, {'role': 'assistant', 'content': 'Sure, I can help you with that. When do you want to do that?'}, {'role': 'user', 'content': 'added schedule: {\\'kind\\': \\'calendar#events\\', \\'etag\\': \\'\"p32c8n7dku7b880o\"\\', \\'summary\\': \\'mesenlee123@gmail.com\\', \\'description\\': \\'\\', \\'updated\\': \\'2024-03-03T00:57:06.543Z\\', \\'timeZone\\': \\'Europe/Berlin\\', \\'accessRole\\': \\'owner\\', \\'defaultReminders\\': [{\\'method\\': \\'popup\\', \\'minutes\\': 30}], \\'nextSyncToken\\': \\'CJiLnbTx1oQDEJiLnbTx1oQDGAUg2tKJogIo2tKJogI=\\', \\'items\\': [{\\'kind\\': \\'calendar#event\\', \\'etag\\': \\'\"3418854853086000\"\\', \\'id\\': \\'jejvdnu14l3fnvb4p262cteejo\\', \\'status\\': \\'confirmed\\', \\'htmlLink\\': \\'https://www.google.com/calendar/event?eid=amVqdmRudTE0bDNmbnZiNHAyNjJjdGVlam8gbWVzZW5sZWUxMjNAbQ\\', \\'created\\': \\'2024-03-03T00:57:06.000Z\\', \\'updated\\': \\'2024-03-03T00:57:06.543Z\\', \\'summary\\': \\'running\\', \\'location\\': \\'KIT\\', \\'creator\\': {\\'email\\': \\'mesenlee123@gmail.com\\', \\'self\\': True}, \\'organizer\\': {\\'email\\': \\'mesenlee123@gmail.com\\', \\'self\\': True}, \\'start\\': {\\'dateTime\\': \\'2024-03-03T01:55:55+01:00\\', \\'timeZone\\': \\'Europe/Berlin\\'}, \\'end\\': {\\'dateTime\\': \\'2024-03-03T01:55:55+01:00\\', \\'timeZone\\': \\'Europe/Berlin\\'}, \\'iCalUID\\': \\'jejvdnu14l3fnvb4p262cteejo@google.com\\', \\'sequence\\': 0, \\'reminders\\': {\\'useDefault\\': False, \\'overrides\\': [{\\'method\\': \\'email\\', \\'minutes\\': 1440}, {\\'method\\': \\'popup\\', \\'minutes\\': 10}]}, \\'eventType\\': \\'default\\'}]}what is the added schedule?'}, {'role': 'assistant', 'content': 'Alright, I have put that in your calendar. 📅'}, {'role': 'user', 'content': 'user_input: get schedule. user_input:  Given retrievaled context: get schedule   get an activity.'}, {'role': 'assistant', 'content': 'You can find your schedule for today in your calendar.'}, {'role': 'user', 'content': 'get schedule: {\\'kind\\': \\'calendar#events\\', \\'etag\\': \\'\"p32gb975vubb880o\"\\', \\'summary\\': \\'mesenlee123@gmail.com\\', \\'description\\': \\'\\', \\'updated\\': \\'2024-03-03T01:01:58.036Z\\', \\'timeZone\\': \\'Europe/Berlin\\', \\'accessRole\\': \\'owner\\', \\'defaultReminders\\': [{\\'method\\': \\'popup\\', \\'minutes\\': 30}], \\'nextSyncToken\\': \\'CKC0nL_y1oQDEKC0nL_y1oQDGAUg2tKJogIo2tKJogI=\\', \\'items\\': [{\\'kind\\': \\'calendar#event\\', \\'etag\\': \\'\"3418854853086000\"\\', \\'id\\': \\'jejvdnu14l3fnvb4p262cteejo\\', \\'status\\': \\'confirmed\\', \\'htmlLink\\': \\'https://www.google.com/calendar/event?eid=amVqdmRudTE0bDNmbnZiNHAyNjJjdGVlam8gbWVzZW5sZWUxMjNAbQ\\', \\'created\\': \\'2024-03-03T00:57:06.000Z\\', \\'updated\\': \\'2024-03-03T00:57:06.543Z\\', \\'summary\\': \\'running\\', \\'location\\': \\'KIT\\', \\'creator\\': {\\'email\\': \\'mesenlee123@gmail.com\\', \\'self\\': True}, \\'organizer\\': {\\'email\\': \\'mesenlee123@gmail.com\\', \\'self\\': True}, \\'start\\': {\\'dateTime\\': \\'2024-03-03T01:55:55+01:00\\', \\'timeZone\\': \\'Europe/Berlin\\'}, \\'end\\': {\\'dateTime\\': \\'2024-03-03T01:55:55+01:00\\', \\'timeZone\\': \\'Europe/Berlin\\'}, \\'iCalUID\\': \\'jejvdnu14l3fnvb4p262cteejo@google.com\\', \\'sequence\\': 0, \\'reminders\\': {\\'useDefault\\': False, \\'overrides\\': [{\\'method\\': \\'email\\', \\'minutes\\': 1440}, {\\'method\\': \\'popup\\', \\'minutes\\': 10}]}, \\'eventType\\': \\'default\\'}]}what has user gotten'}, {'role': 'assistant', 'content': 'Here is the schedule for today: You have running planned. 🏃\\u200d♂️'}, {'role': 'user', 'content': 'user_input: delete schedule. user_input:  Given retrievaled context: delete schedule   delete an activity.'}, {'role': 'assistant', 'content': 'Sure, I can help you with that. What exactly do you want to delete?'}, {'role': 'user', 'content': \"removed schedule: (Empty DataFrame\\nColumns: [event_id, summary, start_date_time, end_date_time, time_zone, location, status, attendees, creation_date, last_modified_date, reminders, embedding]\\nIndex: [], 'Event with ID jejvdnu14l3fnvb4p262cteejo has been deleted from both Google Calendar and DataFrame.')what has user delete\"}, {'role': 'assistant', 'content': 'Alright, I deleted the activity for you. 🗑'}, {'role': 'user', 'content': 'user_input: well done!!. user_input: '}, {'role': 'assistant', 'content': \"Well done! You have completed the activity. I'm proud of you! 💪👍\"}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from google.auth.transport.requests import Request\n",
    "import os\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import datetime\n",
    "# 如果修改了授权范围，删除旧的 token.json 文件\n",
    "\"\"\"if os.path.exists(\"token.json\"):\n",
    "    os.remove(\"token.json\")\n",
    "\"\"\"\n",
    "SCOPES = [\"https://www.googleapis.com/auth/calendar\"]\n",
    "creds = None\n",
    "    # 检查是否有可用的授权令牌\n",
    "if os.path.exists(\"token.json\"):\n",
    "    creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "    # 如果没有有效的凭证，让用户登录。\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            \"client_secret_2_452665542359-3fc9a1q5lcg222qt6uvh3dgbes2n9ktr.apps.googleusercontent.com.json\", SCOPES\n",
    "        )\n",
    "        creds = flow.run_local_server(port=0)\n",
    "        # 保存凭证以供下次运行使用\n",
    "    with open(\"token.json\", \"w\") as token:\n",
    "        token.write(creds.to_json())\n",
    "\n",
    "def get_answer_with_context(client, model, messages):\n",
    "    \"\"\"\n",
    "    Using the given OpenAI client and model, generate answers based on the provided list of messages.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(model=model, messages=messages,max_tokens=300)\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the problem: {e}\")\n",
    "        return \"Unable to get answer\"\n",
    "def format_output(context, user_mood, current_timestamp):\n",
    "    \n",
    "    output = ''\n",
    "\n",
    "    if context:\n",
    "        output += '. background knowledge: ' + context\n",
    "\n",
    "    output += '. user mood: ' + user_mood\n",
    "\n",
    "\n",
    "    output += '. ' + current_timestamp\n",
    "\n",
    "    return output\n",
    "\n",
    "# Set OpenAI API key\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Set up the model\n",
    "model = fine_tuned_model_name\n",
    "\n",
    "#Initial conversation message\n",
    "print(\"Hi, I'm a chatbot for Behavioral Activation Therapy, focusing on positive activities and problem-solving. Talk to me about anything. 😊\")\n",
    "#Initial conversation message\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful chatbot that based on Behavioural activation treatment. Your answer must be less than 3 sentences. Explain BA understandably at first and chatbot makes a self-introduction. You used Google Calendar API so that user can use order to add event, get event and delete event. Add event order is add schedule. Get event order is get schedule. Delete event order is delete schedule. Find activities that user likes and encourage the user to take part in them. Encourage users to share their goals and activities publicly, such as on twitter. The social pressure and potential for public accountability can be a strong incentive. Encourage users to share their goals and activities to their friends and family so that they can supervise users’ activities and try to prevent users from avoiding participating in activities. Remind users to check their finished und uncompleted schedule. Encourage users when they complete activities and remind users to remember and share the joy of successful completion of schedules. If depression or anxiety is detected, chatbot need offer comforting words, suggestions, or techniques for emotion regulation. Given some context, you must give a suitable response based on the context.\"}, {\"role\": \"assistant\", \"content\": \"Hi, I'm a chatbot for Behavioral Activation Therapy, focusing on positive activities and problem-solving. Talk to me about anything. 😊\"},\n",
    "]\n",
    "user_input_count = 0\n",
    "user_mood = \"\"\n",
    "\n",
    "while True:\n",
    "    # Ask the user to enter a question\n",
    "    user_input = input(\"This is an fine-tuned model.\\n Please enter your text (or enter 'exit' to end): \").strip()\n",
    "    if user_input.lower() == 'exit' or user_input.lower() == '':\n",
    "        if user_input_count > 4: \n",
    "            save_messages_to_jsonl(messages,folder_path)\n",
    "        print('messages: ',messages)\n",
    "        chat_messages = messages\n",
    "        break\n",
    "    # increment counter\n",
    "    user_input_count += 1\n",
    "    print(\"user_input \" + str(user_input_count) + \": \" + user_input)\n",
    "\n",
    "    print(\"###############################\")\n",
    "    # Execute mood_track every five user inputs\n",
    "    if user_input_count % 5 == 0 and user_input_count>4 :\n",
    "        user_mood = mood_track(knowledge_df, 0.1)\n",
    "        print('user_mood: ',user_mood)\n",
    "        print(\"###############################\")\n",
    "       \n",
    "    current_timestamp = get_current_timestamp()\n",
    "    context = dataframe_to_string(extract_knowledges_from_df(knowledge_df, user_input, 0.3))\n",
    "    #schedule = dataframe_to_string(extract_knowledges_from_df(schedule_df, user_input, 0.1))\n",
    "\n",
    "    formatted_output = format_output(context, user_mood, current_timestamp)\n",
    "\n",
    "    print('context: ',context)\n",
    "    print(\"###############################\")\n",
    "    # Add user message to conversation\n",
    "    messages.append({\"role\": \"user\", \"content\": \"user_input: \"+user_input +\". user_input: \"+ context})\n",
    "    # Get and print answers\n",
    "    answer = get_answer_with_context(client, model, messages)\n",
    "    print(\"Answer:\", answer)\n",
    "    print(\"###############################\")\n",
    "    # Add assistant's answers to conversation\n",
    "    messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    \n",
    "    # Implement schedule related operations: use\n",
    "    #extract_knowledges_from_df(df,\"new schedule\",0.3)\n",
    "    if extract_activity_from_df(knowledge_df,user_input,0.15)==\"add schedule .\":\n",
    "        schedule_df,event_id = add_event(schedule_df)\n",
    "        messages.append({\"role\": \"user\", \"content\": \"added schedule: \"+str(get_event_with_eventId(event_id)) + \"what is the added schedule?\"})\n",
    "        answer = get_answer_with_context(client, model, messages)\n",
    "        print(\"Answer:\", answer)\n",
    "        print(\"###############################\")\n",
    "        # Add assistant's answers to conversation\n",
    "        messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    elif extract_activity_from_df(knowledge_df,user_input,0.15)==\"get schedule .\":\n",
    "        summary = input(\"input your summary of event\")\n",
    "        location = input(\"input your location of event\")\n",
    "        startTime = input(\"input your startTime of event\")\n",
    "        endTime = input(\"input your endTime of event\")\n",
    "        get_schedule = get_event_without_eventId(schedule_df, summary, location, startTime, endTime)\n",
    "        messages.append({\"role\": \"user\", \"content\": \"get schedule: \"+str(get_schedule)+ \"what has user gotten\"})\n",
    "        answer = get_answer_with_context(client, model, messages)\n",
    "        print(\"Answer:\", answer)\n",
    "        print(\"###############################\")\n",
    "        # Add assistant's answers to conversation\n",
    "        messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        \n",
    "    if extract_activity_from_df(knowledge_df,user_input,0.3)==\"delete schedule .\":\n",
    "        summary = input(\"input your summary of event\")\n",
    "        location = input(\"input your location of event\")\n",
    "        startTime = input(\"input your startTime of event\")\n",
    "        endTime = input(\"input your endTime of event\")\n",
    "        delete_schedule=delete_event_without_eventId(schedule_df, summary, location, startTime, endTime)\n",
    "        messages.append({\"role\": \"user\", \"content\": \"removed schedule: \"+str(delete_schedule)+ \"what has user delete\"})\n",
    "        answer = get_answer_with_context(client, model, messages)\n",
    "        print(\"Answer:\", answer)\n",
    "        print(\"###############################\")\n",
    "        # Add assistant's answers to conversation\n",
    "        messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [event_id, summary, start_date_time, end_date_time, time_zone, location, status, attendees, creation_date, last_modified_date, reminders, embedding]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_id</th>\n      <th>summary</th>\n      <th>start_date_time</th>\n      <th>end_date_time</th>\n      <th>time_zone</th>\n      <th>location</th>\n      <th>status</th>\n      <th>attendees</th>\n      <th>creation_date</th>\n      <th>last_modified_date</th>\n      <th>reminders</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:38:01.298787900Z",
     "start_time": "2024-03-03T00:38:01.264787800Z"
    }
   },
   "id": "3fa41ea7a047938e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finished tasks\n",
    "1. Mood track (passive and active)\n",
    "2. BA Introduction: Explain BA understandably at first and chatbot makes a self-introduction\n",
    "3. Public Declaration: encourage users to share their goals and activities publicly, such as on twitter. The social pressure and potential for public accountability can be a strong incentive.\n",
    "4. Partner Supervision: encourage users to share their goals and activities to their friends and family so that they can supervise users’ activities and try to prevent users from avoiding participating in activities.\n",
    "5. Implementation of Activity Recommendation\n",
    "6. Implementation of Incentive mechanism(Public Declaration,Partner Supervision,Schedule Check-in history,Compliment and Praises)\n",
    "7. Schedule Management  (possible solution: Use 2 dfs, 1. Knowlegde(read only) 2.Schedule(read and write))\n",
    "8. Compliment and Praises: encourage users when they complete activities and remind users to remember and share the joy of successful completion of schedules\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27edd53ef930675"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Updated functions\n",
    "1. modified schedule management\n",
    "2. modified the schedule table. It contains too less information. New columns: \n",
    "3. new prompt construction: Mood Intervention: If depression or anxiety is detected, chatbot need offer comforting words, suggestions, or techniques for emotion regulation. \n",
    "4. Google calendar API\n",
    "5. reduce information overload"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae806dbf74f3b949"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T00:37:32.235958300Z",
     "start_time": "2024-03-03T00:37:32.181435500Z"
    }
   },
   "id": "cddb34da97774d1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
